{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating map from csv file \n",
    "\n",
    "1. data is [from](https://earthdata.nasa.gov/earth-observation-data/near-real-time/firms/viirs-i-band-active-fire-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convert a mulitpart geometry into seprate geometries, the geometry is after subject to mapshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "# from shapely.geometry.polygon import Polygon\n",
    "# from shapely.geometry.multipolygon import MultiPolygon\n",
    "\n",
    "# def explode(gdf):\n",
    "#     \"\"\" \n",
    "#     Explodes a geodataframe \n",
    "    \n",
    "#     Will explode muti-part geometries into single geometries. Original index is\n",
    "#     stored in column level_0 and zero-based count of geometries per multi-\n",
    "#     geometry is stored in level_1\n",
    "    \n",
    "#     Args:\n",
    "#         gdf (gpd.GeoDataFrame) : input geodataframe with multi-geometries\n",
    "        \n",
    "#     Returns:\n",
    "#         gdf (gpd.GeoDataFrame) : exploded geodataframe with a new index \n",
    "#                                  and two new columns: level_0 and level_1\n",
    "        \n",
    "#     \"\"\"\n",
    "#     gs = gdf.explode()\n",
    "#     gdf2 = gs.reset_index().rename(columns={0: 'geometry'})\n",
    "#     gdf_out = gdf2.merge(gdf.drop('geometry', axis=1), left_on='level_0', right_index=True)\n",
    "#     gdf_out = gdf_out.set_index(['level_0', 'level_1']).set_geometry('geometry')\n",
    "#     gdf_out.crs = gdf.crs\n",
    "#     return gdf_out\n",
    "\n",
    "indata='../data/vector/India_states.json'\n",
    "gdf=gpd.GeoDataFrame.from_file(indata)\n",
    "# qq=explode(gdf)\n",
    "gdf.to_file('India_states.shp', driver='ESRI Shapefile')\n",
    "#gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f76251aba90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T20:16:58.863479Z",
     "start_time": "2018-09-27T20:14:51.335460Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pysal/__init__.py:65: VisibleDeprecationWarning: PySAL's API will be changed on 2018-12-31. The last release made with this API is version 1.14.4. A preview of the next API version is provided in the `pysal` 2.0 prelease candidate. The API changes and a guide on how to change imports is provided at https://pysal.org/about\n",
      "  ), VisibleDeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed 0/365 in 2017\n",
      "completed 1/365 in 2017\n",
      "completed 2/365 in 2017\n",
      "completed 3/365 in 2017\n",
      "completed 4/365 in 2017\n",
      "completed 5/365 in 2017\n",
      "completed 6/365 in 2017\n",
      "completed 7/365 in 2017\n",
      "completed 8/365 in 2017\n",
      "completed 9/365 in 2017\n",
      "completed 10/365 in 2017\n",
      "completed 11/365 in 2017\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from numpy import linspace\n",
    "from shapely.geometry import Point, Polygon, MultiPoint, MultiPolygon\n",
    "from descartes import PolygonPatch\n",
    "import geopandas\n",
    "from osgeo import gdal\n",
    "from shapely.geometry import LineString\n",
    "from pysal.esda.mapclassify import Natural_Breaks as nb\n",
    "from pysal.esda.mapclassify import User_Defined as ud\n",
    "import fiona\n",
    "import os\n",
    "from os.path import exists\n",
    "import sys\n",
    "import matplotlib.patheffects as pe\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO\n",
    "\n",
    "\n",
    "dba = pd.read_csv('../data/vector/fire_archive_V1_2871.csv')\n",
    "\n",
    "\n",
    "\n",
    "def lookup(s):\n",
    "    \"\"\"\n",
    "    This is an extremely fast approach to datetime parsing.\n",
    "    For large data, the same dates are often repeated. Rather than\n",
    "    re-parse these, we store all unique dates, parse them, and\n",
    "    use a lookup to convert all dates.\n",
    "    \"\"\"\n",
    "    return s.map({date:pd.to_datetime(date) for date in s.unique()})\n",
    "\n",
    "dba.loc[:,'date']=lookup(dba['acq_date'])\n",
    "\n",
    "dba['monthday'] = dba['date'].dt.strftime('%j')\n",
    "dba['fileformate'] = dba['date'].dt.strftime('%Y_%m_%d')\n",
    "dba['year'] = dba['date'].dt.strftime('%Y')\n",
    "\n",
    "\n",
    "yearlist=dba.drop_duplicates('year')\n",
    "yearlist1=yearlist['year'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################\n",
    "# choose dpi\n",
    "\n",
    "dpichos=300\n",
    "\n",
    "###########################\n",
    "#speicify the path location of the script file, in which folder the shape file and data csv file has to be placed\n",
    "\n",
    "path=\"./\"\n",
    "os.chdir(path)\n",
    "\n",
    "############################\n",
    "#location of the legend to show, choose legendpos=left or right, comment the line otherwise\n",
    "\n",
    "#left=fig.add_axes([0.12, 0.1, 0.04, 0.25]) \n",
    "\n",
    "#right=fig.add_axes([0.8, 0.1, 0.03, 0.3]) \n",
    "#[left,right,height, width]\n",
    "#legendpos=left\n",
    "\n",
    "############################\n",
    "#the background color, chnage the string 'w' to get different colors\n",
    "\n",
    "tbg='w'\n",
    "\n",
    "###########################\n",
    "#output file type, edit the outputtype into '.jpg' to get it in jpg  \n",
    "\n",
    "outputtype='.png'\n",
    "\n",
    "##########################\n",
    "# resolution/size, edit size into small to get the ouptut in small size \n",
    "\n",
    "India=[8.6,8.6]\n",
    "\n",
    "size=India\n",
    "\n",
    "##########################\n",
    "#get the exxtent of shape file, state shape file read and takes the extent values from it\n",
    "\n",
    "shp = fiona.open('India_states.shp')\n",
    "bds = shp.bounds\n",
    "shp.close()\n",
    "extra = 0.01\n",
    "ll = (bds[0], bds[1])\n",
    "ur = (bds[2], bds[3])\n",
    "coords = list(chain(ll, ur))\n",
    "w, h = coords[2] - coords[0], coords[3] - coords[1]\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "#does reading of shape file and make a pandas datframe and read csv file to attach it with shape file\n",
    "for year in yearlist1:\n",
    "    dba1=dba[dba['year']=='2017']\n",
    "    daylist=dba1.drop_duplicates('monthday')\n",
    "    daylist1=daylist['monthday'].tolist()\n",
    "    for indef,houre in enumerate(daylist1[0:12]):\n",
    "        df5e=dba1[dba1.monthday==houre]\n",
    "        df5e['daye']=pd.to_datetime(df5e['acq_date'], format='%Y-%m-%d')\n",
    "        df5e['day1'] = df5e['daye'].dt.strftime('%Y-%b-%d')\n",
    "        timet=df5e.iloc[-1]['day1']\n",
    "        date=df5e.iloc[0]['fileformate']\n",
    "        newfilename='viirs_'+date\n",
    "        fig = plt.figure()\n",
    "        statepa = fig.add_subplot(111, facecolor=tbg, frame_on=False)\n",
    "        amap = Basemap(epsg=24374,lon_0=19.17,lat_0=72.98,ellps = 'WGS84',llcrnrlon=coords[0],llcrnrlat=coords[1],urcrnrlon=coords[2]+0.8,urcrnrlat=coords[3],lat_ts=0,resolution='i',suppress_ticks=True, ax=statepa)\n",
    "        amap.readshapefile('India_states','India_states',color='none',zorder=2)\n",
    "        df_map = pd.DataFrame({'geometry': [Polygon(xy) for xy in amap.India_states],'censuscode': [state['censuscode'] for state in amap.India_states_info]})\n",
    "        df_map['patches'] = df_map['geometry'].map(lambda x: PolygonPatch(x,fc='#d7dac2',ec='#ffffff', lw=.85, alpha=.9,zorder=4))\n",
    "        ###READING THE FIRE DATA\n",
    "        map_points = pd.Series([Point(amap(mapped_x, mapped_y)) for mapped_x, mapped_y in zip(df5e['longitude'], df5e['latitude'])])\n",
    "        dev = amap.scatter([geom.x for geom in map_points],[geom.y for geom in map_points],1, marker='o', lw=0,facecolor='r', edgecolor='b',alpha=0.6, antialiased=True,label='Active fire locations', zorder=3)\n",
    "        statepa.add_collection(PatchCollection(df_map['patches'].values, match_original=True))\n",
    "        x1,y1=amap(85.0,31.0)\n",
    "        plt.text(x1, y1, 'Himalayas', fontsize=12,fontweight='bold',ha='left',va='center',color='k')\n",
    "        x1,y1=amap(67.0,16.0)\n",
    "        plt.text(x1, y1, 'Arabian Sea', fontsize=12,fontweight='bold',ha='left',va='center',color='k')\n",
    "        x1,y1=amap(85.2,13.0)\n",
    "        plt.text(x1, y1, 'Bay of Bengal', fontsize=12,fontweight='bold',ha='left',va='center',color='k')\n",
    "        x1,y1=amap(81.0,39.0)\n",
    "        plt.text(x1, y1, 'Open Fires Detected on '+timet, fontsize=15,fontweight='bold',ha='center',va='center',color='k')\n",
    "        citations='Source: NRT VIIRS 375 m \\nActive Fire product VNP14IMGT. \\nAvailable on-line [https://earthdata.nasa.gov/firms]. \\nDOI:10.5067/FIRMS/VIIRS/VNP14IMGT.NRT.001.'\n",
    "        x1,y1=amap(66.0,7.5)\n",
    "        plt.text(x1, y1, citations, fontsize=6,fontweight='bold',ha='left',va='center',color='k')\n",
    "        fig.set_size_inches(size[0],size[1])\n",
    "        plt.savefig(newfilename+outputtype, dpi=dpichos, alpha=True)\n",
    "        plt.close(fig)\n",
    "        print(\"completed \"+str(indef)+\"/365 in \"+str(year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45121 entries, 0 to 45120\n",
      "Data columns (total 18 columns):\n",
      "latitude       45121 non-null float64\n",
      "longitude      45121 non-null float64\n",
      "bright_ti4     45121 non-null float64\n",
      "scan           45121 non-null float64\n",
      "track          45121 non-null float64\n",
      "acq_date       45121 non-null object\n",
      "acq_time       45121 non-null int64\n",
      "satellite      45121 non-null object\n",
      "instrument     45121 non-null object\n",
      "confidence     45121 non-null object\n",
      "version        45121 non-null int64\n",
      "bright_ti5     45121 non-null float64\n",
      "frp            45121 non-null float64\n",
      "daynight       0 non-null float64\n",
      "date           45121 non-null datetime64[ns]\n",
      "monthday       45121 non-null object\n",
      "fileformate    45121 non-null object\n",
      "year           45121 non-null object\n",
      "dtypes: datetime64[ns](1), float64(8), int64(2), object(7)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dba.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bright_ti4</th>\n",
       "      <th>scan</th>\n",
       "      <th>track</th>\n",
       "      <th>acq_date</th>\n",
       "      <th>acq_time</th>\n",
       "      <th>satellite</th>\n",
       "      <th>instrument</th>\n",
       "      <th>confidence</th>\n",
       "      <th>version</th>\n",
       "      <th>bright_ti5</th>\n",
       "      <th>frp</th>\n",
       "      <th>daynight</th>\n",
       "      <th>date</th>\n",
       "      <th>monthday</th>\n",
       "      <th>fileformate</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.94264</td>\n",
       "      <td>64.14420</td>\n",
       "      <td>305.9</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2213</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>275.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>335</td>\n",
       "      <td>2017_12_01</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.76704</td>\n",
       "      <td>70.33032</td>\n",
       "      <td>315.2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2212</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>277.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>335</td>\n",
       "      <td>2017_12_01</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.79974</td>\n",
       "      <td>64.64509</td>\n",
       "      <td>320.2</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2211</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>272.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>335</td>\n",
       "      <td>2017_12_01</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.98457</td>\n",
       "      <td>74.85178</td>\n",
       "      <td>305.5</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2037</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>284.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>335</td>\n",
       "      <td>2017_12_01</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.16106</td>\n",
       "      <td>80.28531</td>\n",
       "      <td>337.2</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2037</td>\n",
       "      <td>N</td>\n",
       "      <td>VIIRS</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>278.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>335</td>\n",
       "      <td>2017_12_01</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude  bright_ti4  scan  track    acq_date  acq_time  \\\n",
       "0  30.94264   64.14420       305.9  0.39   0.59  2017-12-01      2213   \n",
       "1  33.76704   70.33032       315.2  0.72   0.75  2017-12-01      2212   \n",
       "2  38.79974   64.64509       320.2  0.54   0.51  2017-12-01      2211   \n",
       "3  12.98457   74.85178       305.5  0.39   0.36  2017-12-01      2037   \n",
       "4  13.16106   80.28531       337.2  0.47   0.48  2017-12-01      2037   \n",
       "\n",
       "  satellite instrument confidence  version  bright_ti5  frp  daynight  \\\n",
       "0         N      VIIRS          n        1       275.3  1.2       NaN   \n",
       "1         N      VIIRS          n        1       277.7  3.2       NaN   \n",
       "2         N      VIIRS          n        1       272.0  2.3       NaN   \n",
       "3         N      VIIRS          n        1       284.4  1.5       NaN   \n",
       "4         N      VIIRS          n        1       278.0  4.9       NaN   \n",
       "\n",
       "        date monthday fileformate  year  \n",
       "0 2017-12-01      335  2017_12_01  2017  \n",
       "1 2017-12-01      335  2017_12_01  2017  \n",
       "2 2017-12-01      335  2017_12_01  2017  \n",
       "3 2017-12-01      335  2017_12_01  2017  \n",
       "4 2017-12-01      335  2017_12_01  2017  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stitching image into animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-27T20:20:12.654319Z",
     "start_time": "2018-09-27T20:19:26.551241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test.mp4\n",
      "[MoviePy] Writing video test.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 48/49 [00:35<00:01,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mpy\n",
    "import os\n",
    "import glob\n",
    "\n",
    "pngfiles=glob.glob('./*png')\n",
    "output_base_name='test.mp4'\n",
    "aa=[1]*len(pngfiles[0:2])\n",
    "clip = mpy.ImageSequenceClip(pngfiles[0:2], durations=aa, load_images=True)\n",
    "clip.write_videofile(output_base_name,audio=False,fps=24 )\n",
    "\n",
    "#pngfiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "from IPython.display import HTML\n",
       "<video width=\"700\" height=\"700\" controls>\n",
       "  <source src=\"test.mp4\" type=\"video/mp4\">\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "from IPython.display import HTML\n",
    "<video width=\"700\" height=\"700\" controls>\n",
    "  <source src=\"test.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "31px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
